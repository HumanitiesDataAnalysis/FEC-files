{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import fecfile\n",
    "from fecfile.fecparser import Fecfile\n",
    "import random\n",
    "import glob\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFecfile(object):\n",
    "    def __init__(self, fname, encoding = \"unicode\"):\n",
    "        self.fname = fname\n",
    "        self.date = fname.parts[1]\n",
    "        self.basename = fname.with_suffix('').name\n",
    "        # self.data = fecfile.from_file(fname)\n",
    "            \n",
    "    def cache_forms(self):\n",
    "        z = self.typed_frames()\n",
    "        for frame in z:\n",
    "            try:\n",
    "                form = frame.form_type[0]\n",
    "            except IndexError:\n",
    "                continue\n",
    "            except AttributeError:\n",
    "                if 'rec_type' in frame.columns:\n",
    "                    # Usually \"TEXT\". So whatevs.\n",
    "                    continue\n",
    "                else:\n",
    "                    print(frame.columns)\n",
    "                    continue\n",
    "            dir = f\"cache/{self.date}/{form}\"\n",
    "            if not os.path.exists(dir):\n",
    "                os.makedirs(dir)\n",
    "            frame.to_parquet(f\"{dir}/{self.basename}.parquet\", allow_truncated_timestamps=True)\n",
    "        cached_forms.add(self.basename)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"<FEC filing>\" + str(self.fname)\n",
    "    \n",
    " \n",
    "    def typed_frames(self, encoding = None):\n",
    "        file = fecfile.fecparser.Fecfile(self.fname)\n",
    "        file.prepare_itemization_buffers()\n",
    "        frames = []\n",
    "        for key in file.forms.keys():\n",
    "            key = key.decode(\"utf-8\")\n",
    "            try:\n",
    "                frame = file.to_pandas(key)\n",
    "                frames.append(frame)\n",
    "            except ValueError: # Duplicate names--others may be more pernicious.\n",
    "                continue\n",
    "            except:\n",
    "                print(key)\n",
    "                raise\n",
    "                continue\n",
    "        return frames\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Path(\"fec/20200305/1388022.fec\").exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Datefecs():\n",
    "    def __init__(self, date):\n",
    "        self.path = Path(f\"raw/{date}\")\n",
    "        self.date = date\n",
    "    def wrapup(self):\n",
    "        \"\"\"\n",
    "        Combine all the files of the same form type together for any given date.\n",
    "        \"\"\"\n",
    "        date = self.date\n",
    "        base = Path(f\"cache/{date}\")\n",
    "        for form_group in base.glob(\"*\"):\n",
    "            formtype = form_group.name\n",
    "            parquet_loc = base / Path(formtype).with_suffix(\".parquet\")\n",
    "            if parquet_loc.is_file():\n",
    "                continue\n",
    "            files = []\n",
    "            for filename in form_group.glob(\"*.parquet\"):\n",
    "                try:\n",
    "                    file = pd.read_parquet(filename)\n",
    "                except:\n",
    "                    print(f\"File: {filename}\")\n",
    "                    raise\n",
    "                file['source_file'] = filename.with_suffix('').name\n",
    "                files.append(file)\n",
    "            if (len(files)==0):\n",
    "                continue\n",
    "            parquet_loc = base / Path(formtype).with_suffix(\".parquet\")\n",
    "            pd.concat(files).to_parquet(parquet_loc, allow_truncated_timestamps=True)\n",
    "    def filings(self):\n",
    "        for f in Path(f\"fec/{self.date}\").glob(\"*.fec\"):\n",
    "            yield Fecfile(f)\n",
    "    def nth(self, ix):\n",
    "        for i, r in enumerate(self.filings()):\n",
    "            if i == ix:\n",
    "                return r\n",
    "    def cache_children(self, force = False):\n",
    "        for f in Path(f\"fec/{self.date}\").glob(\"*.fec\"):\n",
    "            if f.with_suffix('').name in cached_forms and not force:\n",
    "                continue\n",
    "            filing = MyFecfile(f)\n",
    "            filing.cache_forms()\n",
    "    \n",
    "r = Datefecs(\"20200305\")\n",
    "r.cache_children()\n",
    "r.wrapup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/bschmidt/Dropbox/lib/fecfile/fecfile']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fecfile.__path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115341"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_paths = [z for z in Path(\"fec\").glob(\"**/*.fec\")]\n",
    "all_dirs = [z for z in Path(\"fec\").glob(\"*\")]\n",
    "\n",
    "random.shuffle(all_paths)\n",
    "random.shuffle(all_dirs)\n",
    "\n",
    "cached_forms = set([z.with_suffix('').with_suffix('').name for z in Path(\"cache\").glob(\"**/*.parquet\")])\n",
    "\n",
    "len(cached_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    7873592    4.181    0.000    4.515    0.000 cache.py:66(getTypeMapping)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "   177015    5.207    0.000   32.687    0.000 fecparser.py:164(parse_line)\n",
    "  7873592    4.181    0.000    4.515    0.000 cache.py:66(getTypeMapping)\n",
    "  7873592    3.506    0.000   19.048    0.000 fecparser.py:187(getTyped)\n",
    " 15785593    2.873    0.000    2.873    0.000 {method 'startswith' of 'str' objects}\n",
    "  1753430    2.868    0.000    2.868    0.000 {method 'replace' of 'datetime.datetime' objects}\n",
    "   178140    2.667    0.000    7.618    0.000 fecparser.py:118(fields_from_line)\n",
    "   175343    1.882    0.000    3.367    0.000 _strptime.py:318(_strptime)\n",
    "  7892234    1.598    0.000    3.041    0.000 fecparser.py:128(<lambda>)\n",
    "   175343    1.530    0.000    6.803    0.000 tzinfo.py:258(localize)\n",
    "8767364/8766948    0.674    0.000    0.674    0.000 {built-in method builtins.len}\n",
    "   177124    0.600    0.000   33.548    0.000 fecparser.py:68(iter_lines)\n",
    "   350686    0.525    0.000    1.881    0.000 tzinfo.py:193(fromutc)\n",
    "   350511    0.510    0.000    0.629    0.000 {method 'add' of 'set' objects}\n",
    "   701516    0.459    0.000    0.459    0.000 {built-in method builtins.max}\n",
    "   179266    0.423    0.000    0.423    0.000 {method 'split' of 'str' objects}\n",
    "     1125    0.396    0.000   34.010    0.030 fecparser.py:45(loads)\n",
    "   701372    0.379    0.000    0.379    0.000 {built-in method _bisect.bisect_right}\n",
    "   350686    0.366    0.000    2.794    0.000 tzinfo.py:203(normalize)\n",
    "   175343    0.350    0.000    3.717    0.000 _strptime.py:574(_strptime_datetime)\n",
    "   287530    0.289    0.000    0.289    0.000 {method 'match' of 're.Pattern' objects}\n",
    "   175343    0.201    0.000    3.918    0.000 {built-in method strptime}\n",
    "   175343    0.196    0.000    0.196    0.000 {built-in method _locale.setlocale}\n",
    "   971325    0.195    0.000    0.195    0.000 {method 'strip' of 'str' objects}\n",
    "   175343    0.180    0.000    0.266    0.000 locale.py:384(normalize)\n",
    "   175979    0.166    0.000    0.193    0.000 cache.py:39(getMapping)\n",
    "        1    0.162    0.162   34.357   34.357 <ipython-input-13-922219bc4e05>:32(cache_children)\n",
    "   430949    0.143    0.000    0.143    0.000 {method 'replace' of 'str' objects}\n",
    "   175343    0.136    0.000    0.710    0.000 locale.py:575(getlocale)\n",
    "   175343    0.135    0.000    0.135    0.000 {method 'groupdict' of 're.Match' objects}\n",
    "   175343    0.127    0.000    0.837    0.000 _strptime.py:26(_getlang)\n",
    "   702098    0.123    0.000    0.123    0.000 {method 'get' of 'dict' objects}\n",
    "   350212    0.119    0.000    0.119    0.000 tzinfo.py:396(utcoffset)\n",
    "   175343    0.112    0.000    0.378    0.000 locale.py:467(_parse_localename)\n",
    "   112190    0.102    0.000    0.214    0.000 re.py:271(_compile)\n",
    "   175999    0.101    0.000    0.101    0.000 fecparser.py:17(__init__)\n",
    "   606292    0.100    0.000    0.100    0.000 {method 'lower' of 'str' objects}\n",
    "   356280    0.081    0.000    0.081    0.000 {built-in method builtins.chr}\n",
    "     1125    0.066    0.000    0.078    0.000 {built-in method io.open}\n",
    "   466570    0.063    0.000    0.063    0.000 {built-in method builtins.isinstance}\n",
    "   350686    0.054    0.000    0.054    0.000 {method 'toordinal' of 'datetime.date' objects}\n",
    "   176005    0.053    0.000    0.053    0.000 {method 'upper' of 'str' objects}\n",
    "     3918    0.048    0.000    0.334    0.000 cache.py:50(getTypeMapping_from_regex)\n",
    "   112187    0.047    0.000    0.309    0.000 re.py:170(match)\n",
    "   112188    0.047    0.000    0.075    0.000 types.py:164(__get__)\n",
    "   181031    0.032    0.000    0.032    0.000 {method 'append' of 'list' objects}\n",
    "   187208    0.030    0.000    0.030    0.000 {method 'keys' of 'dict' objects}\n",
    "   112188    0.028    0.000    0.028    0.000 enum.py:628(value)\n",
    "   175343    0.025    0.000    0.025    0.000 {method 'pop' of 'set' objects}\n",
    "   175343    0.024    0.000    0.024    0.000 {method 'end' of 're.Match' objects}\n",
    "     1125    0.024    0.000    0.039    0.000 {method 'read' of '_io.TextIOWrapper' objects}\n",
    "   175343    0.023    0.000    0.023    0.000 {method 'weekday' of 'datetime.date' objects}\n",
    "     1125    0.020    0.000   34.147    0.030 __init__.py:90(from_file)\n",
    "     1125    0.013    0.000    0.013    0.000 {built-in method _codecs.utf_8_decode}\n",
    "    58494    0.011    0.000    0.011    0.000 {method 'endswith' of 'str' objects}\n",
    "     1125    0.007    0.000   34.165    0.030 <ipython-input-12-c8fea67ea934>:2(__init__)\n",
    "     2250    0.007    0.000    0.018    0.000 pathlib.py:846(with_suffix)\n",
    "     1126    0.005    0.000    0.013    0.000 pathlib.py:523(_select_from)\n",
    "  320/219    0.004    0.000    0.010    0.000 sre_parse.py:469(_parse)\n",
    "     6750    0.004    0.000    0.004    0.000 pathlib.py:790(name)\n",
    "     3375    0.004    0.000    0.006    0.000 pathlib.py:677(_from_parsed_parts)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365\n"
     ]
    }
   ],
   "source": [
    "all_dirs = [z for z in Path(\"fec\").glob(\"*\")]\n",
    "one_year = [dir.name for dir in all_dirs if \"2018\" in dir.name]\n",
    "random.shuffle(one_year)\n",
    "print(len(one_year))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_forms.remove('1377999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20180422\n",
      "20180406\n",
      "20180224\n",
      "20180217\n",
      "20181120\n",
      "20180826\n",
      "20180628\n",
      "20181108\n",
      "20180601\n",
      "20180202\n",
      "20181104\n",
      "20180128\n",
      "20180629\n",
      "20180131\n",
      "20180221\n",
      "20180105\n",
      "20181204\n",
      "20180503\n",
      "20180630\n",
      "20181130\n",
      "20180626\n",
      "20180423\n",
      "20180617\n",
      "20180712\n",
      "20180312\n",
      "20180917\n",
      "20180122\n",
      "20180818\n",
      "20180910\n",
      "20180506\n",
      "20180830\n",
      "20180426\n",
      "20180526\n",
      "20180915\n",
      "20181118\n",
      "20181215\n",
      "20180319\n",
      "20180704\n",
      "20180924\n",
      "20180528\n",
      "20180730\n",
      "20181006\n",
      "20181119\n",
      "20180926\n",
      "20180809\n",
      "20180211\n",
      "20180404\n",
      "20180208\n",
      "20181229\n",
      "20180206\n",
      "20181106\n",
      "20180829\n",
      "20180824\n",
      "20180623\n",
      "20180424\n",
      "20180904\n",
      "20180323\n",
      "20180811\n",
      "20180512\n",
      "20181210\n",
      "20180301\n",
      "20180525\n",
      "20181112\n",
      "20180317\n",
      "20181030\n",
      "20181203\n",
      "20180804\n",
      "20180508\n",
      "20180618\n",
      "20181105\n",
      "20181219\n",
      "20180831\n",
      "20180101\n",
      "20180930\n",
      "20181001\n",
      "20180725\n",
      "20180416\n",
      "20180517\n",
      "20180218\n",
      "20180815\n",
      "20181124\n",
      "20180908\n",
      "20180413\n",
      "20180204\n",
      "20180511\n",
      "20181205\n",
      "20180410\n",
      "20180201\n",
      "20180311\n",
      "20180531\n",
      "20181231\n",
      "20180928\n",
      "20180706\n",
      "20180620\n",
      "__________\n",
      "b'SB30B\\n'\n",
      "Error on 20180620\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-39d247d989ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatefecs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrapup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-20-708049453e53>\u001b[0m in \u001b[0;36mcache_children\u001b[0;34m(self, force)\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mfiling\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMyFecfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m             \u001b[0mfiling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_forms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDatefecs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"20200305\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-1329ce5ee4d9>\u001b[0m in \u001b[0;36mcache_forms\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcache_forms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtyped_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-1329ce5ee4d9>\u001b[0m in \u001b[0;36mtyped_frames\u001b[0;34m(self, encoding)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtyped_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfecfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfecparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFecfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_itemization_buffers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/lib/fecfile/fecfile/fecparser.py\u001b[0m in \u001b[0;36mprepare_itemization_buffers\u001b[0;34m(self, sep)\u001b[0m\n\u001b[1;32m    122\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m                 \u001b[0mform\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34mb\"\\n\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "cached_forms\n",
    "for date in one_year:\n",
    "    print(date)\n",
    "    try:\n",
    "        r = Datefecs(date)\n",
    "        r.cache_children()\n",
    "        r.wrapup()\n",
    "    except KeyboardInterrupt:\n",
    "        break\n",
    "    except:\n",
    "        print(f\"Error on {date}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = Datefecs(\"20181013\")\n",
    "#r.cache_children()\n",
    "#r.wrapup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, dir in enumerate(Path(\"fec\").glob(\"201*\")):\n",
    "    print(dir)\n",
    "    filings = dir.glob(\"*.fec\")\n",
    "    for file in filings:\n",
    "        try:\n",
    "           Fecfile(file).cache_forms()\n",
    "        except UnicodeDecodeError:\n",
    "            pass\n",
    "    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all = [\n",
    "    \n",
    "]\n",
    "\n",
    "for p in Path(\"cache\").glob(\"2019*/SA1[17]*.parquet\"):\n",
    "    d = pd.read_parquet(p)\n",
    "    v = pd.DataFrame({\n",
    "        'recipient': d.filer_committee_id_number, \n",
    "        'donor': (d.contributor_first_name + d.contributor_last_name + d.contributor_organization_name + d.contributor_zip_code.str[:5]).str.upper(),\n",
    "        'amt': d.contribution_amount\n",
    "    })\n",
    "    # Prefer FEC ids to mashing together names.\n",
    "    v.loc[d.donor_committee_fec_id != \"\", 'donor'] = d.donor_committee_fec_id[d.donor_committee_fec_id != \"\"]\n",
    "    v.loc[d.donor_candidate_fec_id != \"\", 'donor'] = d.donor_candidate_fec_id[d.donor_candidate_fec_id != \"\"]\n",
    "    \n",
    "    all.append((v))\n",
    "    if len(all) % 25 == 0:\n",
    "        print((p, len(all)))\n",
    " #   if len(all) > 200:\n",
    " #       break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals = pd.concat(all)\n",
    "counts = totals.groupby([\"recipient\", \"donor\"])['amt'].sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.to_parquet(\"total_2019_network.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "counts = pd.read_parquet(\"total_2019_network.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter down to donors with at least 5 recipients and vice versa\n",
    "thresh = 3\n",
    "last_shape = 0\n",
    "current_shape = counts.shape[0]\n",
    "while last_shape != current_shape:\n",
    "\n",
    "    print(current_shape)\n",
    "    last_shape = counts.shape[0]\n",
    "    counts['recipient_count']= counts.recipient.map(counts.recipient.value_counts())\n",
    "    counts = counts[counts['recipient_count'] >= thresh]\n",
    "    counts['donor_count']= counts.donor.map(counts.donor.value_counts())\n",
    "    counts = counts[counts['donor_count'] >= thresh]\n",
    "    counts = counts[counts.amt > 0] # Yerg negative is just confusing\n",
    "    current_shape = counts.shape[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_table = counts.groupby(\"recipient\")['amt'].sum().reset_index().rename(columns = {\"recipient\":\"ix\", \"amt\": \"receipts\"}).merge(\n",
    "    counts.groupby(\"donor\")['amt'].sum().reset_index().rename(columns = {\"donor\":\"ix\", \"amt\": \"donations\"}), how='outer').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "committees = pd.read_csv(\"committee_summary_2020.csv\")[[\"CMTE_ID\", \"CMTE_NM\", \"CMTE_CITY\", \"CMTE_ST\", \"ORG_TP\"]]\n",
    "committees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = individual_table.merge(committees, left_on = \"ix\", right_on = \"CMTE_ID\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = dinodct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts.sort_values(\"amt\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sparse1 = np.zeros((counts.shape[0], 3), np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contribs = open(\"/Users/bschmidt/contribs.edgelist\", \"w\")\n",
    "for i, row in enumerate(counts.iterrows()):\n",
    "    recipient, donor, amount, n , _ = row[1]\n",
    "    if not recipient in id_list:\n",
    "        id_list[recipient] = len(id_list)\n",
    "    if not donor in id_list:\n",
    "        id_list[donor] = len(id_list)\n",
    "    contribs.write(f\"{id_list[recipient]}\\t{id_list[donor]}\\t{np.log(amount)}\\n\")\n",
    "    sparse1[i] = [id_list[recipient], id_list[donor], np.log(amount)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/Users/bschmidt/snap/examples/node2vec/node2vec -i:/Users/bschmidt/contribs.edgelist -v -o:/Users/bschmidt/embedding_1.bin -l:20 -k:4 -d:32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want the backwards lookup, too.\n",
    "reversed_dict = {v: k for k, v in id_list.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import scipy.sparse\n",
    "#sparsified = scipy.sparse.coo_matrix((sparse1[:,2], (sparse1[:,1], sparse1[:,0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = SRP.Vector_file(\"/Users/bschmidt/embedding_1.bin\").to_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x['matrix'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "embedded = umap.UMAP(n_neighbors=20, random_state=1, low_memory=False).fit_transform(x['matrix'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em2 = pd.DataFrame(embedded, columns = ['x', 'y'])\n",
    "em2['ix'] = range(em2.shape[0])\n",
    "em2['ix'].replace(reversed_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em2 = em2.merge(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em2['label'] = em2['ix']\n",
    "del em2['ix']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em2.to_csv(\"~/embedded_2.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em2.sort_values(\"receipts\", ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(em2.sort_values(\"receipts\", ascending = False).head(300)).mark_circle().encode(x = \"x\", y = \"y\", tooltip=\"CMTE_NM\", size=\"receipts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:HTRC]",
   "language": "python",
   "name": "conda-env-HTRC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
